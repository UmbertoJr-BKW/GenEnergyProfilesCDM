{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d0280b6-76cf-4b4c-9c36-39c4981365e9",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models (DDPMs) for Profile Generation (PG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f25664-3a1f-4a73-b4f4-76d0f0ca290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from dl_models import Model\n",
    "from data_process import DataSet\n",
    "from utils import AverageMeter, ProgressMeter\n",
    "from diffusion_process import DiffusionProcess\n",
    "from visualizations import scatter, update_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d43446-fd3b-4669-8305-2a25a2cfe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_fn(self, x, idx=None):\n",
    "    # Calculate the loss function\n",
    "    output, epsilon, alpha_bar = self.forward(x, idx=idx, get_target=True)\n",
    "    loss = (output - epsilon).square().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd9908a-ead8-4a21-8844-7d569c69d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  \n",
    "import math  \n",
    "  \n",
    "# Assuming these are defined in your code  \n",
    "n_steps = 96  \n",
    "input_dim = 1\n",
    "nhead = 16\n",
    "num_layers = 3\n",
    "hidden_dim = 64\n",
    "batch_size=32\n",
    "  \n",
    "# Create an instance of the model  \n",
    "model = Backbone(n_steps, input_dim, hidden_dim=hidden_dim, nhead=nhead, num_layers=num_layers)  \n",
    "  \n",
    "# Create a tensor of random numbers to represent your input data  \n",
    "input_data = torch.randn(batch_size, n_steps, input_dim)  \n",
    "  \n",
    "# Create a tensor of random numbers to represent your index  \n",
    "index = torch.randint(high=n_steps, size=(batch_size,))  \n",
    "  \n",
    "# Run the data through the model  \n",
    "output = model(input_data, index)  \n",
    "  \n",
    "# Print the output  \n",
    "print(output.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3061c-3199-4a5f-927a-5b3b0e5e5059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c28e4-115f-44a7-9e46-375ec73b720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, device, beta_1, beta_T, T, input_dim):\n",
    "        '''\n",
    "        Parameters:\n",
    "        device: str or torch.device object\n",
    "            The device to use for the model\n",
    "        beta_1: float\n",
    "            The value of beta at time t = 1\n",
    "        beta_T: float\n",
    "            The value of beta at time t = T (the final time)\n",
    "        T: int\n",
    "            The number of time steps\n",
    "        input_dim: int\n",
    "            The input dimension of the model\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.T = T\n",
    "\n",
    "        \n",
    "        def cosine_schedule(T, s):\n",
    "            t_vec = np.arange(T)\n",
    "            f_t = np.cos([(t/T + s)/(1+s) * np.pi/2 for t in t_vec])**2\n",
    "            alphabar_t = f_t/ f_t[0]\n",
    "            return alphabar_t\n",
    "        # Calculate alpha bars\n",
    "        self.alpha_bars = torch.Tensor(cosine_schedule(T,200)).to(device = device)\n",
    "        #self.alpha_bars = torch.cumprod(1 - torch.linspace(start = beta_1, end=beta_T, steps=T), dim = 0).to(device = device)\n",
    "        \n",
    "        # Create the backbone module\n",
    "        #file_dir = \"first_attempt_model.pth\"\n",
    "        #self.backbone = torch.load(file_dir)\n",
    "        # Assuming these are defined in your code  \n",
    "        n_steps = 96  \n",
    "        nhead = 16\n",
    "        num_layers = 3\n",
    "        hidden_dim = 64\n",
    "        \n",
    "        self.backbone = Backbone(n_steps=n_steps, input_dim=1, \n",
    "                                 hidden_dim=hidden_dim, nhead=nhead, \n",
    "                                 num_layers=num_layers, T=T)\n",
    "\n",
    "        # Move the model to the device\n",
    "        self.to(device = self.device)\n",
    "\n",
    "\n",
    "    def loss_fn(self, x, idx=None):\n",
    "        # Calculate the loss function\n",
    "        output, epsilon, alpha_bar = self.forward(x, idx=idx, get_target=True)\n",
    "        loss = (output - epsilon).square().mean()\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x, idx=None, get_target=False):\n",
    "        if not isinstance(idx, int):\n",
    "            idx = torch.randint(0, self.T, (x.size(0), )).to(device = self.device)\n",
    "            #print(idx.shape)\n",
    "            used_alpha_bars = self.alpha_bars[idx[:, None]][:, None]\n",
    "            #print(used_alpha_bars.shape)\n",
    "            epsilon = torch.randn_like(x)\n",
    "            x_tilde = torch.sqrt(used_alpha_bars) * x + torch.sqrt(1 - used_alpha_bars) * epsilon\n",
    "        else:\n",
    "            x_tilde = x\n",
    "            idx = torch.full((x.shape[0], ), idx)\n",
    "        \n",
    "        \n",
    "        #print(x_tilde.shape, idx.shape)\n",
    "        # Pass x_tilde and idx through the backbone module\n",
    "        output = self.backbone(x_tilde, idx)\n",
    "\n",
    "        return (output, epsilon, used_alpha_bars) if get_target else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6563d35-e8e1-4431-9e75-661d863347f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for beta_1, beta_T, T, shape, device\n",
    "beta_1 = 1e-4\n",
    "beta_T = 0.02\n",
    "T = 1000\n",
    "shape = (96, 1)\n",
    "device = \"cpu\" #torch.device('cuda')\n",
    "\n",
    "\n",
    "# Create the Model instance and the Diffusion Process\n",
    "model = Model(device, beta_1, beta_T, T, 1)\n",
    "\n",
    "# Run the data through the model  \n",
    "output = model(input_data, index)\n",
    "output = model(input_data)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81901255-90d2-44ff-a77d-790bc17b1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DiffusionProcess class\n",
    "class DDPM():\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, beta_1, beta_T, T, diffusion_fn, device, shape):\n",
    "        '''\n",
    "        \n",
    "        Parameters:\n",
    "        beta_1: float\n",
    "            The value of beta at time t = 1\n",
    "        beta_T: float\n",
    "            The value of beta at time t = T (the final time)    \n",
    "        T: int\n",
    "            The number of time steps\n",
    "        diffusion_fn: function\n",
    "            The function that defines the diffusion process\n",
    "        device: str or torch.device object  \n",
    "            The device to use for the diffusion process\n",
    "        shape: tuple    \n",
    "            The shape of the diffusion process\n",
    "        '''\n",
    "        self.betas = torch.linspace(start = beta_1, end=beta_T, steps=T)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.T = T\n",
    "        self.alpha_bars = torch.cumprod(1 - torch.linspace(start = beta_1, \n",
    "                                                           end=beta_T,\n",
    "                                                           steps=T), \n",
    "                                        dim = 0).to(device = device)\n",
    "        self.alpha_prev_bars = torch.cat([torch.Tensor([1]).to(device=device), self.alpha_bars[:-1]])\n",
    "        self.shape = shape\n",
    "        self.diffusion_fn = diffusion_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def q_xt(self, x0, t):\n",
    "        mu = x0 * np.sqrt(self.alpha_bars[t])\n",
    "        sigma = 1 - self.alpha_bars[t]\n",
    "        return mu + sigma * np.random.randn(*x0.shape)\n",
    "\n",
    "    def _one_diffusion_step(self, x):\n",
    "        '''\n",
    "        \n",
    "        Parameters:\n",
    "        x: torch.Tensor\n",
    "            The input tensor for the diffusion process \n",
    "        '''\n",
    "        # Perform one diffusion step\n",
    "        for idx in reversed(range(self.T)):\n",
    "            noise = torch.zeros_like(x) if idx == 0 else torch.randn_like(x)\n",
    "            sqrt_tilde_beta = torch.sqrt((1 - self.alpha_prev_bars[idx]) / (1 - self.alpha_bars[idx]) * self.betas[idx])\n",
    "            \n",
    "            idx_t = torch.Tensor([int(idx) for _ in range(x.size(0))]).to(device = self.device).long()\n",
    "            \n",
    "            idx_t_repeated = idx_t.repeat(0, 96)  \n",
    "            idx_t = idx_t_repeated[:, :, None]  \n",
    "            \n",
    "            #print(x.shape, idx_t.shape)\n",
    "            predict_epsilon = self.diffusion_fn(x, idx_t)\n",
    "            mu_theta_xt = torch.sqrt(1 / self.alphas[idx]) * (x - self.betas[idx] / torch.sqrt(1 - self.alpha_bars[idx]) * predict_epsilon)\n",
    "            x = mu_theta_xt + sqrt_tilde_beta * noise\n",
    "            yield x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sampling(self, sampling_number, only_final=False):\n",
    "        # Perform sampling from the diffusion process\n",
    "        sample = torch.randn([sampling_number,*self.shape]).to(device = self.device).squeeze()\n",
    "        sample = sample[:, :, None]\n",
    "        sampling_list = []\n",
    "\n",
    "        final = None\n",
    "        for idx, sample in enumerate(self._one_diffusion_step(sample)):\n",
    "            final = sample\n",
    "            if not only_final:\n",
    "                sampling_list.append(final)\n",
    "\n",
    "        return final if only_final else torch.stack(sampling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3945a58-83e6-4b28-89dd-d23c464045e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../../data_exploration/data.csv')  \n",
    "  \n",
    "transformed_df = df.copy()  \n",
    "transformed_df['Id'] = transformed_df['Id'].astype(str)  \n",
    "transformed_df['Timestamp'] = pd.to_datetime(transformed_df['Timestamp'])  \n",
    "  \n",
    "# Append the date to the Id before converting the 'Timestamp' to time  \n",
    "transformed_df['Id'] = transformed_df['Id'] + ' - ' + transformed_df['Timestamp'].dt.date.astype(str)  \n",
    "transformed_df['Timestamp'] = transformed_df['Timestamp'].dt.time  \n",
    "  \n",
    "# Group by 'Id' and 'Timestamp' and calculate the mean of 'Energy_Consumption'  \n",
    "transformed_df = transformed_df.groupby(['Id', 'Timestamp'])['Energy_Consumption'].mean().reset_index()  \n",
    "  \n",
    "# Pivot the table  \n",
    "transformed_df = transformed_df.pivot(index='Id', columns='Timestamp', values='Energy_Consumption') \n",
    "\n",
    "# Drop the NaN values\n",
    "transformed_df = transformed_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f48d16-de5f-45e0-8738-ca0ebd08eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import rotate\n",
    "from IPython.display import HTML\n",
    "from IPython.display import clear_output\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d714d-edff-44ae-a023-912c211dccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):      \n",
    "    def __init__(self, df):  \n",
    "        #df = df.diff()  \n",
    "        df = df.dropna()  # drop NaN values after diff operation  \n",
    "        self.df = self.scale(df)  \n",
    "        self.total_len = len(self.df)  \n",
    "      \n",
    "    def scale(self, df):    \n",
    "        # Scale the data    \n",
    "        df_scaled = pd.DataFrame(df, columns=df.columns, index=df.index)  \n",
    "        df_scaled.values /=\n",
    "        return df_scaled    \n",
    "    \n",
    "    def inverse_scale(self, df):    \n",
    "        # Inverse scale the data    \n",
    "        df_inv_scaled = pd.DataFrame(self.inverse_scaler(df), columns=df.columns, index=df.index)    \n",
    "        return df_inv_scaled   \n",
    "    \n",
    "    def __len__(self):    \n",
    "        return self.total_len    \n",
    "    \n",
    "    def __getitem__(self, idx):      \n",
    "        data = self.df.iloc[idx].values    \n",
    "        return torch.from_numpy(data).float().unsqueeze(-1)   \n",
    "\n",
    "\n",
    "transformed_df = transformed_df[(transformed_df <= 10).all(axis=1)]  \n",
    "\n",
    "# Create a DataSet instance  \n",
    "dataset = DataSet(transformed_df)  \n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                        batch_size = batch_size, \n",
    "                                        drop_last = True)\n",
    "\n",
    "dataiterator = iter(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e251e-a2e9-48ea-b7be-bac98dd8a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81a1ae-2847-49df-af18-bd45274f9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_schedule(T, s):\n",
    "    t_vec = np.arange(T)\n",
    "    f_t = np.cos([(t/T + s)/(1+s) * np.pi/2 for t in t_vec])**2\n",
    "    alphabar_t = f_t/ f_t[0]\n",
    "    beta_t = np.array([min(1 - a_t/a_t1, 0.999) for a_t, a_t1 in zip(alphabar_t[1:], alphabar_t[:-1])])\n",
    "    alpha_t = 1 - beta_t\n",
    "    return beta_t, alpha_t, alphabar_t\n",
    "\n",
    "def linear_schedule(beta_min, beta_max, T):\n",
    "    beta_t = np.linspace(beta_min, beta_max, T)\n",
    "    alpha_t = 1 - beta_t\n",
    "    alphabar_t = np.cumprod(alpha_t)\n",
    "    return beta_t, alpha_t, alphabar_t\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ab53d-6838-4f12-b0af-43a3a4a20202",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_min, beta_max = 1e-5, 0.02\n",
    "T = 100\n",
    "s = 200\n",
    "\n",
    "beta_t_lin, alpha_t_lin, alphabar_t_lin = linear_schedule(beta_min, beta_max, T)  \n",
    "beta_t_cos, alpha_t_cos, alphabar_t_cos = cosine_schedule(T, s) \n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))  \n",
    "  \n",
    "plt.subplot(1,3,1)  \n",
    "plt.plot(beta_t_cos, label='Cosine')  \n",
    "plt.plot(beta_t_lin, label='Linear')  \n",
    "plt.title('Beta')  \n",
    "plt.legend()  \n",
    "  \n",
    "plt.subplot(1,3,2)  \n",
    "plt.plot(alpha_t_cos, label='Cosine')  \n",
    "plt.plot(alpha_t_lin, label='Linear')  \n",
    "plt.title('Alpha')  \n",
    "plt.legend()  \n",
    "  \n",
    "plt.subplot(1,3,3)  \n",
    "plt.plot(alphabar_t_cos, label='Cosine')  \n",
    "plt.plot(alphabar_t_lin, label='Linear')  \n",
    "plt.title('Alpha Bar')  \n",
    "plt.legend()  \n",
    "  \n",
    "plt.tight_layout()  \n",
    "plt.show()  \n",
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "# Assuming tensor is your input tensor\n",
    "tensor = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b5e8a-2100-4062-b19c-a8c644679316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "# Assuming tensor is your input tensor\n",
    "tensor = next(iter(dataloader))\n",
    "\n",
    "tensor_numpy = tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1641c46-5588-4c9d-a199-0b4185eb21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the values for beta_1, beta_T, T, shape, device\n",
    "shape = (96, 1)\n",
    "\n",
    "\n",
    "process = DDPM(beta_1, beta_T, T, model, device, shape=shape)\n",
    "\n",
    "t = int((T-1)/2)\n",
    "\n",
    "output_t = process.q_xt(tensor, t)\n",
    "\n",
    "# Convert tensor to numpy array  \n",
    "numpy_data = output_t.numpy()  \n",
    "\n",
    "\n",
    "\n",
    "# Create a figure and a set of subplots  \n",
    "fig, ax = plt.subplots()  \n",
    "\n",
    "#scat = plt.scatter(scatter_x, scatter_y, s=1)\n",
    "\n",
    "# This will create a line for each row in your data. If that's too many lines,  \n",
    "# you might need to select a subset of rows to plot.  \n",
    "for i in range(numpy_data.shape[0]):  \n",
    "    ax.plot(numpy_data[i, :], alpha=0.1)  \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe5160-9b84-47fe-a73a-0931ad08ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_xt(x0, t, alpha_bars):\n",
    "        mu = x0 * np.sqrt(alpha_bars[t])\n",
    "        sigma = 1 - alpha_bars[t]\n",
    "        return mu + sigma * np.random.randn(*x0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9242a-c1d7-476c-8716-0af765d4da5d",
   "metadata": {},
   "source": [
    "## Linear Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee1d46-2bae-43c3-b863-9d951473bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celluloid import Camera    \n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "camera = Camera(fig)  \n",
    "for t in range(0, T, 10):\n",
    "    for sample in range(tensor_numpy.shape[0]):\n",
    "        time_sample_t = q_xt(tensor_numpy[sample], t, alphabar_t_lin)\n",
    "        ax.plot(time_sample_t, alpha=0.1)  \n",
    "    \n",
    "    # Add text showing frequency  \n",
    "    text = ax.text(0.8, .8, f'Time: {t}', transform=ax.transAxes) \n",
    "    camera.snap()  \n",
    "    \n",
    "    \n",
    "animation = camera.animate()  \n",
    "  \n",
    "# Save as GIF  \n",
    "animation.save('evolution_lin.gif', writer='pillow')  \n",
    "  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3076ea0-e6a0-4566-a35f-57930e0a5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "Image(filename=\"evolution_lin.gif\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d9ccb4-1703-4e03-b43d-81a405b47739",
   "metadata": {},
   "source": [
    "## Cosine schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b425a8-fbeb-419e-9410-1f57fd12b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celluloid import Camera    \n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "camera = Camera(fig)  \n",
    "for t in range(0, T, 10):\n",
    "    for sample in range(tensor_numpy.shape[0]):\n",
    "        time_sample_t = q_xt(tensor_numpy[sample], t, alphabar_t_cos)\n",
    "        ax.plot(time_sample_t, alpha=0.1)  \n",
    "    \n",
    "    # Add text showing frequency  \n",
    "    text = ax.text(0.8, 0.8, f'Time: {t}', transform=ax.transAxes) \n",
    "    camera.snap()  \n",
    "    \n",
    "    \n",
    "animation = camera.animate()  \n",
    "  \n",
    "# Save as GIF  \n",
    "animation.save('evolution_cos.gif', writer='pillow')  \n",
    "  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1c7e9-51e1-487a-a05e-8e71b3482a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "Image(filename=\"evolution_cos.gif\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e56733e-4e8d-4d4b-99ab-f7f74895d7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4edce9f6-9b45-48f3-9de1-795fc62156c6",
   "metadata": {},
   "source": [
    "## Random signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1758b-ad8b-4a94-93e9-50442138b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celluloid import Camera    \n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "camera = Camera(fig)  \n",
    "for t in range(0, T, 1000):\n",
    "    for sample in range(tensor_numpy.shape[0]):\n",
    "        time_sample_t = np.random.randn(96)\n",
    "        ax.plot(time_sample_t, alpha=0.1)  \n",
    "    \n",
    "    # Add text showing frequency  \n",
    "    text = ax.text(0.8, .8, f'Time: {t}', transform=ax.transAxes) \n",
    "    camera.snap()  \n",
    "    \n",
    "    \n",
    "animation = camera.animate()  \n",
    "  \n",
    "# Save as GIF  \n",
    "animation.save('evolution_random.gif', writer='pillow')  \n",
    "  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3786c-b64a-4ef6-ba63-1a8fe30c268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "Image(filename=\"evolution_random.gif\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59429592-1aa5-49b3-9aaf-9b71037d3e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7af08b5-3c42-4967-97ba-c9ce42d48af2",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea30d89-8d43-42c6-a70e-5c5eca36473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the values for beta_1, beta_T, T, shape, device\n",
    "beta_1 = 1e-5\n",
    "beta_T = 0.02\n",
    "T = 100\n",
    "shape = (96, 1)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "# Create the Model instance and the Diffusion Process\n",
    "#model = Model(device, beta_1, beta_T, T, 1)\n",
    "#process = DiffusionProcess(beta_1, beta_T, T, model, device, shape=shape)\n",
    "#process = DDPM(beta_1, beta_T, T, model, device, shape=shape)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfd1d0-c1c6-4474-ada3-cb934bd14474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for training\n",
    "total_iteration = 10000000\n",
    "current_iteration = 131000\n",
    "t_range = 10000\n",
    "display_iteration = [i for i in range(1, total_iteration, t_range)]\n",
    "sampling_number = 50\n",
    "only_final = True\n",
    "\n",
    "# Set parameters for visualization of the training process\n",
    "losses = AverageMeter('Loss', ':.4f')\n",
    "progress = ProgressMeter(total_iteration, [losses], prefix='Iteration ')\n",
    "\n",
    "\n",
    "# Start the training \n",
    "while current_iteration != total_iteration:\n",
    "    try:\n",
    "        data = next(dataiterator)\n",
    "    except:\n",
    "        dataiterator = iter(dataloader)\n",
    "        data = next(dataiterator)\n",
    "    \n",
    "    data = data.to(device = device)\n",
    "    loss = model.loss_fn(data)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "     # `clip_value` is the upper limit for the gradient.  \n",
    "    # This line does the actual clipping of gradients.  \n",
    "    #torch.nn.utils.clip_grad_norm_(model.parameters(), 1)  \n",
    "  \n",
    "    # Proceed with the optimization step \n",
    "    optim.step()\n",
    "\n",
    "     # Check if the loss is NaN or Inf  \n",
    "    if torch.isnan(loss).item() or torch.isinf(loss).item():  \n",
    "        print(\"The loss is NaN or Inf\")  \n",
    "        print(data)\n",
    "        print(model(data))\n",
    "        break  \n",
    "        \n",
    "    losses.update(loss.item())\n",
    "    progress.display(current_iteration)\n",
    "    current_iteration += 1\n",
    "\n",
    "    if current_iteration in display_iteration:\n",
    "        process = DDPM(beta_1, beta_T, T, model, device, shape)\n",
    "        sample = process.sampling(sampling_number, only_final)\n",
    "        sample = sample.detach().cpu().numpy()\n",
    "        \n",
    "        # Create a figure and a set of subplots  \n",
    "        fig, ax = plt.subplots()  \n",
    "\n",
    "        # This will create a line for each row in your data. If that's too many lines,  \n",
    "        # you might need to select a subset of rows to plot.  \n",
    "        for i in range(sample.shape[0]):  \n",
    "            ax.plot(sample[i, :], alpha=0.1)  \n",
    "\n",
    "        plt.show()  \n",
    "        losses.reset()\n",
    "        torch.save(model.backbone, 'good_noise_model1.pth')\n",
    "        \n",
    "torch.save(model.backbone, 'good_noise_model1.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9309244-4109-46ee-b232-7f4dc91ea7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process = DDPM(beta_1, beta_T, T, model, device, shape)\n",
    "sample = process.sampling(sampling_number, only_final=False)\n",
    "sample = sample.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()  \n",
    "camera = Camera(fig)  \n",
    "for t in range(0, T, 10):\n",
    "    for i in range(tensor_numpy.shape[0]):\n",
    "        ax.plot(sample[t, i, :], alpha=0.1)\n",
    "    \n",
    "    # Add text showing frequency  \n",
    "    text = ax.text(0.8, 0.8, f'Time: {t}', transform=ax.transAxes) \n",
    "    camera.snap()  \n",
    "    \n",
    "    \n",
    "animation = camera.animate()  \n",
    "  \n",
    "# Save as GIF  \n",
    "animation.save('evolution_ddpm.gif', writer='pillow')  \n",
    "  \n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f78ee-2526-4480-9b4e-256f6220cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "Image(filename=\"evolution_ddpm.gif\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512fe6-9b75-484c-889e-fdfe2acd4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DiffusionProcess class\n",
    "class DDPM():\n",
    "\n",
    "    # Initialize the class\n",
    "    def __init__(self, beta_1, beta_T, T, diffusion_fn, device, shape):\n",
    "        '''\n",
    "        \n",
    "        Parameters:\n",
    "        beta_1: float\n",
    "            The value of beta at time t = 1\n",
    "        beta_T: float\n",
    "            The value of beta at time t = T (the final time)    \n",
    "        T: int\n",
    "            The number of time steps\n",
    "        diffusion_fn: function\n",
    "            The function that defines the diffusion process\n",
    "        device: str or torch.device object  \n",
    "            The device to use for the diffusion process\n",
    "        shape: tuple    \n",
    "            The shape of the diffusion process\n",
    "        '''\n",
    "        def cosine_schedule(T, s):\n",
    "            t_vec = np.arange(T)\n",
    "            f_t = np.cos([(t/T + s)/(1+s) * np.pi/2 for t in t_vec])**2\n",
    "            alphabar_t = f_t/ f_t[0]\n",
    "            beta_t = np.array([min(1 - a_t/a_t1, 0.999)] + [min(1 - a_t/a_t1, 0.999) for a_t, a_t1 in zip(alphabar_t[1:], alphabar_t[:-1])])\n",
    "            alpha_t = 1 - beta_t\n",
    "            return beta_t, alpha_t, alphabar_t\n",
    "        \n",
    "        beta, alpha, alphabar = cosine_schedule(T, 200)\n",
    "        print(beta.shape, alpha.shape, alphabar.shape)\n",
    "        # Calculate alpha bars\n",
    "        self.alpha_bars = torch.Tensor(alphabar).to(device = device)\n",
    "        self.betas = torch.Tensor(beta).to(device = device)\n",
    "        self.alphas = torch.Tensor(alpha).to(device = device)\n",
    "        #self.alpha_bars = torch.cumprod(1 - torch.linspace(start = beta_1, end=beta_T, steps=T), dim = 0).to(devi\n",
    "        #self.betas = torch.linspace(start = beta_1, end=beta_T, steps=T)\n",
    "        #self.alphas = 1 - self.betas\n",
    "        self.T = T\n",
    "        #self.alpha_bars = torch.cumprod(1 - torch.linspace(start = beta_1, \n",
    "         #                                                  end=beta_T,\n",
    "          #                                                 steps=T), \n",
    "           #                             dim = 0).to(device = device)\n",
    "        \n",
    "        self.alpha_prev_bars = torch.cat([torch.Tensor([1]).to(device=device), self.alpha_bars[:-1]])\n",
    "        self.shape = shape\n",
    "        self.diffusion_fn = diffusion_fn\n",
    "        self.device = device\n",
    "        \n",
    "    def q_xt(self, x0, t):\n",
    "        mu = x0 * np.sqrt(self.alpha_bars[t])\n",
    "        sigma = 1 - self.alpha_bars[t]\n",
    "        return mu + sigma * np.random.randn(*x0.shape)\n",
    "\n",
    "    def _one_diffusion_step(self, x):\n",
    "        '''\n",
    "        \n",
    "        Parameters:\n",
    "        x: torch.Tensor\n",
    "            The input tensor for the diffusion process \n",
    "        '''\n",
    "        # Perform one diffusion step\n",
    "        for idx in reversed(range(self.T)):\n",
    "            noise = torch.zeros_like(x) if idx == 0 else torch.randn_like(x)\n",
    "            sqrt_tilde_beta = torch.sqrt((1 - self.alpha_prev_bars[idx]) / (1 - self.alpha_bars[idx]) * self.betas[idx])\n",
    "            \n",
    "            idx_t = torch.Tensor([int(idx) for _ in range(x.size(0))]).to(device = self.device).long()\n",
    "            \n",
    "            idx_t_repeated = idx_t.repeat(1, 96)  \n",
    "            idx_t = idx_t_repeated[:, :, None]  \n",
    "            \n",
    "            #print(x.shape, idx_t.shape)\n",
    "            predict_epsilon = self.diffusion_fn(x, idx_t)\n",
    "            mu_theta_xt = torch.sqrt(1 / self.alphas[idx]) * (x - self.betas[idx] / torch.sqrt(1 - self.alpha_bars[idx]) * predict_epsilon)\n",
    "            x = mu_theta_xt \n",
    "            #+ sqrt_tilde_beta * noise\n",
    "            yield x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sampling(self, sampling_number, only_final=False):\n",
    "        # Perform sampling from the diffusion process\n",
    "        sample = torch.randn([sampling_number,*self.shape]).to(device = self.device).squeeze()\n",
    "        sample = sample[:, :, None]\n",
    "        sampling_list = []\n",
    "\n",
    "        final = None\n",
    "        for idx, sample in enumerate(self._one_diffusion_step(sample)):\n",
    "            final = sample\n",
    "            if not only_final:\n",
    "                sampling_list.append(final)\n",
    "\n",
    "        return final if only_final else torch.stack(sampling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382bb8c-007e-478d-93d5-08923741062e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3124b0b0-a95c-486f-97d4-885eaaf9e48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ff6bfe-314d-44a3-98f4-53b5a4782d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233f575-4c41-4488-9dd7-e36fc70cd022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44150dd0-4a6a-49cf-b195-65ea92b7fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7907b9-1a15-4c4f-bc4d-6a2879c2242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_number = 100\n",
    "only_final = True\n",
    "\n",
    "process = DDPM(beta_1, beta_T, T, model, device, shape=shape)\n",
    "sample = process.sampling(sampling_number, only_final)\n",
    "#scatter(sample[9::30], only_final)\n",
    "\n",
    "sample = sample.detach().cpu().numpy()\n",
    "\n",
    "# Create a figure and a set of subplots  \n",
    "fig, ax = plt.subplots()  \n",
    "  \n",
    "# This will create a line for each row in your data. If that's too many lines,  \n",
    "# you might need to select a subset of rows to plot.  \n",
    "for i in range(sample.shape[1]):  \n",
    "    ax.plot(sample[ i, :], alpha=0.1)  \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f77317-b819-4dd0-93f8-220a0a1f69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_number = 100\n",
    "only_final = True\n",
    "\n",
    "\n",
    "# Set the values for beta_1, beta_T, T, shape, device\n",
    "beta_1 = 1e-4\n",
    "beta_T = 0.02\n",
    "T = \n",
    "shape = (96, 1)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "\n",
    "process = DDPM(beta_1, beta_T, T, model, device, shape=shape)\n",
    "sample = process.sampling(sampling_number, only_final)\n",
    "#scatter(sample[9::30], only_final)\n",
    "\n",
    "sample = sample.detach().cpu().numpy()\n",
    "\n",
    "# Create a figure and a set of subplots  \n",
    "fig, ax = plt.subplots()  \n",
    "  \n",
    "# This will create a line for each row in your data. If that's too many lines,  \n",
    "# you might need to select a subset of rows to plot.  \n",
    "for i in range(sample.shape[1]):  \n",
    "    ax.plot(sample[ i, :], alpha=0.1)  \n",
    "  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b98e3-abbc-491f-994b-5fb8f54dcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "numframes = len(sample)\n",
    "scatter_point = sample[0].detach().cpu().numpy()\n",
    "scatter_x, scatter_y = scatter_point[:,0], scatter_point[:,1]\n",
    "\n",
    "\n",
    "scatter_range = [-10, 10]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.xlim(scatter_range)\n",
    "plt.ylim(scatter_range)\n",
    "scat = plt.scatter(scatter_x, scatter_y, s=1)\n",
    "plt.show()\n",
    "clear_output()\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update_plot, frames=range(numframes), fargs=(sample, scat), interval=50)\n",
    "writergif = animation.PillowWriter(fps=40)\n",
    "\n",
    "ani.save('ddpm_toy1.gif', writer=writergif)\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0713d-500d-4286-afca-25b7a049c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6e295-c772-427e-9e5a-28ed213a89b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7cf36f-1289-446c-871c-af5e7bef03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):  \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  \n",
    "  \n",
    "model = Backbone(n_steps=1000, input_dim=1, nhead=16, num_layers=4)  \n",
    "model = model.to(device)  \n",
    "  \n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128041d9-be5f-4c35-9709-7eccadcc3142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the model    \n",
    "model = Backbone(n_steps=1000, input_dim=1, nhead=16, num_layers=4)    \n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "    \n",
    "# Create dummy data with the correct shape    \n",
    "batch_size = 256\n",
    "x = torch.randn(batch_size, 96, 1).to('cuda' if torch.cuda.is_available() else 'cpu')  # Batch size is now 1    \n",
    "idx = torch.randint(0, 1000, (batch_size, 1)).to('cuda' if torch.cuda.is_available() else 'cpu')  \n",
    "    \n",
    "# Run the data through your model    \n",
    "output = model(x, idx)    \n",
    "  \n",
    "print(\"Output shape:\", output.shape)  \n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
